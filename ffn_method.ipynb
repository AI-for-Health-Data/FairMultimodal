{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49d911db-d797-415e-bb26-46592ff3c1c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers[torch]\n",
      "  Downloading transformers-4.47.0-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from transformers[torch])\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers[torch])\n",
      "  Downloading huggingface_hub-0.26.5-py3-none-any.whl (447 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.8/447.8 kB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from transformers[torch]) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from transformers[torch]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from transformers[torch]) (6.0)\n",
      "Collecting regex!=2019.12.17 (from transformers[torch])\n",
      "  Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/rapids/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers[torch])\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m138.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.4.1 (from transformers[torch])\n",
      "  Using cached safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from transformers[torch]) (4.65.0)\n",
      "Collecting torch (from transformers[torch])\n",
      "  Using cached torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
      "Collecting accelerate>=0.26.0 (from transformers[torch])\n",
      "  Downloading accelerate-1.2.0-py3-none-any.whl (336 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.3/336.3 kB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /opt/conda/envs/rapids/lib/python3.10/site-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (4.6.3)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.24.0->transformers[torch])\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: networkx in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->transformers[torch])\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->transformers[torch])\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->transformers[torch])\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->transformers[torch])\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->transformers[torch])\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->transformers[torch])\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->transformers[torch])\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->transformers[torch])\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->transformers[torch])\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch->transformers[torch])\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch->transformers[torch])\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->transformers[torch])\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Collecting triton==3.1.0 (from torch->transformers[torch])\n",
      "  Using cached triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "Collecting sympy==1.13.1 (from torch->transformers[torch])\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch->transformers[torch])\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from requests->transformers[torch]) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from requests->transformers[torch]) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, safetensors, regex, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, torch, accelerate\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.6.3\n",
      "    Uninstalling typing_extensions-4.6.3:\n",
      "      Successfully uninstalled typing_extensions-4.6.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf 23.6.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "cugraph 23.6.2 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "cuml 23.6.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "dask-cudf 23.6.0 requires cupy-cuda11x>=12.0.0, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-1.2.0 filelock-3.16.1 huggingface-hub-0.26.5 mpmath-1.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 regex-2024.11.6 safetensors-0.4.5 sympy-1.13.1 tokenizers-0.21.0 torch-2.5.1 transformers-4.47.0 triton-3.1.0 typing-extensions-4.12.2\n"
     ]
    }
   ],
   "source": [
    "!/opt/conda/envs/rapids/bin/python -m pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "263f085f-4535-4a81-bdbf-fa01476da042",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "# Reload the file to confirm the embeddings\n",
    "cls_1 = pd.read_csv('cls_embeddings 2.csv')\n",
    "cls_2 = pd.read_csv('patient_embeddings(2).csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f15720fd-97c1-4fc8-92e9-3cc4508de6eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cls_1.columns = cls_1.columns.str.lower()\n",
    "cls_2.columns = cls_2.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91a35b3c-a91a-4c28-8fe7-f26581c1aaef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_on_patient_id = pd.merge(cls_1, cls_2, on='patient_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a635b8c-d2df-43ed-9478-4672a60cc344",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FeedForwardNN(\n",
       "   (fc1): Linear(in_features=1537, out_features=512, bias=True)\n",
       "   (relu): ReLU()\n",
       "   (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
       " ),\n",
       " tensor([[  92.2518,   -4.0654,  -96.9748,  128.2229,   27.2384,   40.5467,\n",
       "           160.0581,  -88.9057, -123.1837, -129.8535],\n",
       "         [   1.6930,   -0.3619,   -0.9373,    2.1001,    0.3246,    0.7136,\n",
       "             2.1164,   -1.3414,   -1.9518,   -1.9935],\n",
       "         [  60.8977,   -2.7809,  -63.7357,   84.5718,   17.9232,   26.7671,\n",
       "           105.4081,  -58.5702,  -81.2424,  -85.6398],\n",
       "         [  73.7007,   -3.2758,  -77.3141,  102.3518,   21.6597,   32.3490,\n",
       "           127.7330,  -70.9092,  -98.3438, -103.6566],\n",
       "         [  30.8414,   -1.5491,  -31.8776,   42.7288,    9.0555,   13.5718,\n",
       "            53.0303,  -29.5533,  -41.0231,  -43.2590]],\n",
       "        grad_fn=<SliceBackward0>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume the CLS embeddings are stored as numerical columns in the file\n",
    "cls_embeddings = merged_on_patient_id.values  # Convert to NumPy array\n",
    "cls_tensor = torch.tensor(cls_embeddings, dtype=torch.float32)  # Convert to tensor\n",
    "\n",
    "# Define the Feed-Forward Neural Network\n",
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedForwardNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the network\n",
    "input_dim = cls_tensor.shape[1]  # Number of features in the CLS embeddings\n",
    "hidden_dim = 512  # Hidden layer size\n",
    "output_dim = 10  # Number of output classes\n",
    "model = FeedForwardNN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Perform a forward pass on the CLS embeddings\n",
    "output = model(cls_tensor)\n",
    "\n",
    "# Display the network architecture and sample output\n",
    "model, output[:5]  # Display first 5 predictions for testing purposes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5bec62-1e0c-4e42-b0b3-886aa8b56a54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
