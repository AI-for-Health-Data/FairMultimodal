import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import re
from tqdm import tqdm

# Functions for Demographics
def calculate_age(dob, intime):
    """Calculate age at time of ICU stay given date of birth and ICU intime."""
    return intime.year - dob.year - ((intime.month, intime.day) < (dob.month, dob.day))

def categorize_age(age):
    """Categorize age into one of four bins."""
    if 15 <= age <= 29:
        return '15-29'
    elif 30 <= age <= 49:
        return '30-49'
    elif 50 <= age <= 69:
        return '50-69'
    else:
        return '70-89'

def categorize_ethnicity(ethnicity):
    """Simplify ethnicity descriptions."""
    ethnicity = ethnicity.upper()
    if ethnicity in ['WHITE', 'WHITE - RUSSIAN', 'WHITE - OTHER EUROPEAN', 'WHITE - BRAZILIAN', 'WHITE - EASTERN EUROPEAN']:
        return 'White'
    elif ethnicity in ['BLACK/AFRICAN AMERICAN', 'BLACK/CAPE VERDEAN', 'BLACK/HAITIAN', 'BLACK/AFRICAN', 'CARIBBEAN ISLAND']:
        return 'Black'
    elif ethnicity in ['HISPANIC OR LATINO', 'HISPANIC/LATINO - PUERTO RICAN', 'HISPANIC/LATINO - DOMINICAN', 'HISPANIC/LATINO - MEXICAN']:
        return 'Hispanic'
    elif ethnicity in ['ASIAN', 'ASIAN - CHINESE', 'ASIAN - INDIAN']:
        return 'Asian'
    else:
        return 'Other'

def categorize_insurance(insurance):
    """Categorize insurance based on keyword matching."""
    ins = insurance.upper()
    if 'MEDICARE' in ins:
        return 'Medicare'
    elif 'PRIVATE' in ins:
        return 'Private'
    elif 'MEDICAID' in ins:
        return 'Medicaid'
    elif 'SELF PAY' in ins:
        return 'Self Pay'
    else:
        return 'Government'

# Functions for Text Preprocessing
def preprocess1(x):
    """
    Remove extra characters, numeric bullet points, and standardize abbreviations.
    """
    y = re.sub(r'\[(.*?)\]', '', x)         
    y = re.sub(r'[0-9]+\.', '', y)           
    y = re.sub(r'dr\.', 'doctor', y)
    y = re.sub(r'm\.d\.', 'md', y)
    y = re.sub(r'admission date:', '', y)
    y = re.sub(r'discharge date:', '', y)
    y = re.sub(r'--|__|==', '', y)
    return y

def preprocessing(df):
    """
    Preprocess the 'TEXT' column of a dataframe: remove newlines, extra whitespace,
    convert to lower case, and apply additional cleanup.
    """
    df = df.copy()
    df['TEXT'] = df['TEXT'].fillna(' ')
    df['TEXT'] = df['TEXT'].str.replace('\n', ' ', regex=False)
    df['TEXT'] = df['TEXT'].str.replace('\r', ' ', regex=False)
    df['TEXT'] = df['TEXT'].apply(str.strip)
    df['TEXT'] = df['TEXT'].str.lower()
    df['TEXT'] = df['TEXT'].apply(lambda x: preprocess1(x))
    return df

# Functions for Outcome Calculations
def calculate_short_term_mortality(icu_stays):
    """
    Create a binary column 'short_term_mortality' based on whether DEATHTIME is present.
    """
    icu_stays['short_term_mortality'] = icu_stays['DEATHTIME'].notnull().astype(int)
    return icu_stays

def calculate_readmission(icu_stays):
    """
    Create a binary column 'readmission_within_30_days' based on whether the next ICU
    admission is within 30 days.
    """
    required = ['DISCHTIME', 'INTIME', 'hadm_id']
    for col in required:
        if col not in icu_stays.columns:
            raise KeyError(f"Column {col} is missing in the input data.")
    
    # Sort by subject, admission time, and ICU intime
    icu_stays = icu_stays.sort_values(by=['subject_id', 'ADMITTIME', 'INTIME'])
    
    # Get the discharge time of the current admission
    icu_stays['current_admission_dischtime'] = icu_stays.groupby(['subject_id', 'hadm_id'])['DISCHTIME'].transform('first')
    
    # For each subject, get the next ICU admission's intime and corresponding hadm_id
    icu_stays['next_admission_icu_intime'] = icu_stays.groupby('subject_id')['INTIME'].shift(-1)
    icu_stays['next_hadm_id'] = icu_stays.groupby('subject_id')['hadm_id'].shift(-1)
    
    # Calculate readmission if the next ICU admission happens within 30 days of the current discharge time
    icu_stays['readmission_within_30_days'] = (
        (icu_stays['next_admission_icu_intime'] - icu_stays['current_admission_dischtime']).dt.days <= 30
    ).astype(int)
    icu_stays['readmission_within_30_days'] = icu_stays['readmission_within_30_days'].fillna(0).astype(int)
    return icu_stays

# Functions for Splitting Text into Chunks
def split_text_to_chunks(text, chunk_size=512):
    """
    Split a text into chunks of a given token size.
    Tokens are defined by whitespace.
    """
    tokens = text.split()
    chunks = [' '.join(tokens[i:i + chunk_size]) for i in range(0, len(tokens), chunk_size)]
    return chunks

def split_into_512_token_columns(text, chunk_size=512):
    """
    Given a text, return a Series with one column per chunk.
    """
    chunks = split_text_to_chunks(text, chunk_size)
    chunk_dict = {f"note_chunk_{i+1}": chunk for i, chunk in enumerate(chunks)}
    return pd.Series(chunk_dict)

# Data Loading & Preprocessing: STRUCTURED DATA
admissions_path = 'ADMISSIONS.csv.gz'
icustays_path   = 'ICUSTAYS.csv.gz'
patients_path   = 'PATIENTS.csv.gz'
notes_path      = 'NOTEEVENTS.csv.gz'  # Used later for unstructured

# Read Admissions data
df_adm = pd.read_csv(admissions_path, compression='gzip', low_memory=False, 
                     usecols=['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME', 'ETHNICITY', 'INSURANCE'])
# Read ICU stays data
df_icustays = pd.read_csv(icustays_path, compression='gzip', low_memory=False, 
                          usecols=['SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID', 'INTIME', 'OUTTIME'])
# Read Patients data
df_patients = pd.read_csv(patients_path, compression='gzip', low_memory=False, 
                          usecols=['SUBJECT_ID', 'DOB', 'GENDER'])
# Read Notes data (used later in unstructured processing)
df_notes = pd.read_csv(notes_path, compression='gzip', low_memory=False, 
                       usecols=['SUBJECT_ID', 'HADM_ID', 'CHARTDATE', 'TEXT'])

# Convert datetime columns for admissions
df_adm['ADMITTIME'] = pd.to_datetime(df_adm['ADMITTIME'], format='%Y-%m-%d %H:%M:%S', errors='coerce')
df_adm['DISCHTIME'] = pd.to_datetime(df_adm['DISCHTIME'], format='%Y-%m-%d %H:%M:%S', errors='coerce')
df_adm['DEATHTIME'] = pd.to_datetime(df_adm['DEATHTIME'], format='%Y-%m-%d %H:%M:%S', errors='coerce')

# Convert datetime columns for ICU stays
df_icustays['INTIME'] = pd.to_datetime(df_icustays['INTIME'], format='%Y-%m-%d %H:%M:%S', errors='coerce')
df_icustays['OUTTIME'] = pd.to_datetime(df_icustays['OUTTIME'], format='%Y-%m-%d %H:%M:%S', errors='coerce')

# Convert DOB in Patients
df_patients['DOB'] = pd.to_datetime(df_patients['DOB'], format='%Y-%m-%d', errors='coerce')

# Convert datetime for Notes (CHARTDATE; note that this may only be a date)
df_notes['CHARTDATE'] = pd.to_datetime(df_notes['CHARTDATE'], format='%Y-%m-%d', errors='coerce')

# Rename columns for consistency
df_adm.rename(columns={'SUBJECT_ID': 'subject_id', 'HADM_ID': 'hadm_id'}, inplace=True)
df_icustays.rename(columns={'SUBJECT_ID': 'subject_id', 'HADM_ID': 'hadm_id'}, inplace=True)
df_patients.rename(columns={'SUBJECT_ID': 'subject_id'}, inplace=True)
df_notes.rename(columns={'SUBJECT_ID': 'subject_id', 'HADM_ID': 'hadm_id'}, inplace=True)

# Merge admissions with ICU stays
df_icu = pd.merge(df_adm, df_icustays, on=['subject_id', 'hadm_id'], how='inner')

# Merge patient demographics (DOB, GENDER) into the ICU dataframe
df_icu = pd.merge(df_icu, df_patients[['subject_id', 'DOB', 'GENDER']], on='subject_id', how='left')

# Calculate patient age at the time of ICU INTIME and assign age category
df_icu['age'] = df_icu.apply(lambda row: calculate_age(row['DOB'], row['INTIME']) 
                             if pd.notnull(row['DOB']) and pd.notnull(row['INTIME']) else np.nan, axis=1)
df_icu['age_category'] = df_icu['age'].apply(lambda x: categorize_age(x) if pd.notnull(x) else 'Unknown')

# Categorize ethnicity and insurance
df_icu['ethnicity_category'] = df_icu['ETHNICITY'].apply(lambda x: categorize_ethnicity(x) if pd.notnull(x) else 'Other')
df_icu['insurance_category'] = df_icu['INSURANCE'].apply(lambda x: categorize_insurance(x) if pd.notnull(x) else 'Other')

# Ensure gender is in a consistent format: male or female
df_icu['gender'] = df_icu['GENDER'].str.lower().apply(lambda x: 'male' if 'm' in x else ('female' if 'f' in x else x))

# Compute outcomes: short-term mortality and readmission
df_icu = calculate_short_term_mortality(df_icu)
df_icu = calculate_readmission(df_icu)

# Select only the first ICU stay per patient (sorted by INTIME)
df_first_icu = df_icu.sort_values(by='INTIME').groupby('subject_id').first().reset_index()

# Save structured first ICU dataset (without time-series features)
df_first_icu.to_csv('final_first_icu_dataset.csv', index=False)
print("Structured dataset (first ICU stay) saved as 'final_first_icu_dataset.csv'.")

# Data Loading & Preprocessing: UNSTRUCTURED NOTES (First 24h Only)

# For unstructured notes, we want to work with the first ICU stay only.
# We already have df_first_icu saved above. Now, we filter notes to the first 24h window.

# Merge notes with the first ICU admission information to get the admission timestamp.
# We use the INTIME from df_first_icu as the reference time.
df_first_icu_for_notes = df_first_icu[['subject_id', 'hadm_id', 'INTIME']].copy()
df_first_icu_for_notes.rename(columns={'INTIME': 'admission_time'}, inplace=True)

# Merge the notes with the first ICU stay admission time.
df_notes_merged = pd.merge(df_notes, df_first_icu_for_notes, on=['subject_id', 'hadm_id'], how='inner')

# Compute hours since admission.
# Note: CHARTDATE is a date only. If you have a more granular CHARTTIME column, use it instead.
df_notes_merged['hours_since_admission'] = (df_notes_merged['CHARTDATE'] - df_notes_merged['admission_time']).dt.total_seconds() / 3600

# Filter to keep only notes written within the first 24 hours after admission.
df_notes_filtered = df_notes_merged[df_notes_merged['hours_since_admission'].between(0, 24)].copy()

# Aggregate notes by subject and hadm_id (concatenate all TEXT entries)
notes_agg = df_notes_filtered.groupby(['subject_id', 'hadm_id'])['TEXT'].apply(lambda texts: " ".join(texts)).reset_index()

# Apply text preprocessing to the aggregated notes
notes_agg = preprocessing(notes_agg)

# (Optional) You can also check note lengths
notes_agg['note_length_chars'] = notes_agg['TEXT'].apply(len)
notes_agg['note_length_words'] = notes_agg['TEXT'].apply(lambda x: len(x.split()))
print("Max note length (chars):", notes_agg['note_length_chars'].max())
print("Max note length (words):", notes_agg['note_length_words'].max())

# (Optional) Split the aggregated text into 512-token chunks
note_chunks_df = notes_agg['TEXT'].apply(split_into_512_token_columns)
notes_agg = pd.concat([notes_agg, note_chunks_df], axis=1)

# Save the unstructured (notes) dataset for the first 24h
notes_agg.to_csv('final_unstructured_24h_notes.csv', index=False)
print("Unstructured notes dataset (first 24h) saved as 'final_unstructured_24h_notes.csv'.")

# Merge Structured & Unstructured Data (Optional)

# Load the saved structured dataset (if needed) and the unstructured notes dataset.
df_structured = pd.read_csv('filtered_structured_output.csv')
df_unstructured = pd.read_csv('final_unstructured_24h_notes.csv')

# For example, merge on subject_id and hadm_id to have a unified view.
df_merged = pd.merge(df_structured, df_unstructured, on=['subject_id', 'hadm_id'], how='left')

# Save the merged dataset.
df_merged.to_csv('merged_first_icu_with_24h_notes.csv', index=False)
print("Merged dataset saved as 'merged_first_icu_with_24h_notes.csv'.")

# Read the unstructured dataset
unstructured_file = 'final_unstructured_24h_notes.csv'
unstructured_df = pd.read_csv(unstructured_file, engine='python', on_bad_lines='skip')
print(f"Unstructured notes data shape: {unstructured_df.shape}")

# Read the structured dataset 
structured_file = 'filtered_structured_output.csv' 
structured_df = pd.read_csv(structured_file)
print(f"Structured data shape: {structured_df.shape}")

# Identify common subject IDs
unstructured_ids = set(unstructured_df['subject_id'].unique())
structured_ids   = set(structured_df['subject_id'].unique())
common_ids = unstructured_ids.intersection(structured_ids)
print(f"Number of common subject IDs: {len(common_ids)}")

# Filter the unstructured dataset to only those common subjects.
filtered_unstructured_df = unstructured_df[unstructured_df['subject_id'].isin(common_ids)].copy()
filtered_unstructured_df.to_csv('filtered_unstructured.csv', index=False)
print("Filtered unstructured dataset saved as 'filtered_unstructured.csv'.")
