{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669b928e-b989-4bd9-991c-44f513c110ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (33138, 171)\n",
      "Dataset columns: ['subject_id', 'ROW_ID', 'hadm_id', 'ICUSTAY_ID', 'FIRST_WARDID', 'LAST_WARDID', 'LOS', 'age', 'female', 'male', 'chartevents_t53', 'chartevents_t211', 'chartevents_t444', 'chartevents_t448', 'chartevents_t506', 'chartevents_t535', 'chartevents_t618', 'chartevents_t642', 'chartevents_t646', 'chartevents_t683', 'chartevents_t763', 'chartevents_t1529', 'chartevents_t8368', 'chartevents_t8555', 'chartevents_t220045', 'chartevents_t220050', 'chartevents_t220051', 'chartevents_t220052', 'chartevents_t220059', 'chartevents_t220060', 'chartevents_t220074', 'chartevents_t220210', 'chartevents_t220292', 'chartevents_t220293', 'chartevents_t220339', 'chartevents_t223761', 'chartevents_t223834', 'chartevents_t223835', 'chartevents_t224161', 'chartevents_t224639', 'chartevents_t224641', 'chartevents_t224684', 'chartevents_t224685', 'chartevents_t224687', 'chartevents_t224688', 'chartevents_t224695', 'chartevents_t224697', 'chartevents_t225185', 'chartevents_t225664', 'chartevents_t226253', 'chartevents_t226707', 'chartevents_t226756', 'chartevents_t226757', 'chartevents_t226758', 'chartevents_t226871', 'chartevents_t226873', 'labevents_t50802', 'labevents_t50804', 'labevents_t50809', 'labevents_t50811', 'labevents_t50813', 'labevents_t50818', 'labevents_t50819', 'labevents_t50820', 'labevents_t50831', 'labevents_t50861', 'labevents_t50862', 'labevents_t50863', 'labevents_t50868', 'labevents_t50878', 'labevents_t50893', 'labevents_t50902', 'labevents_t50912', 'labevents_t50931', 'labevents_t50960', 'labevents_t50970', 'labevents_t51094', 'labevents_t51112', 'labevents_t51114', 'labevents_t51116', 'labevents_t51120', 'labevents_t51146', 'labevents_t51200', 'labevents_t51221', 'labevents_t51222', 'labevents_t51237', 'labevents_t51244', 'labevents_t51248', 'labevents_t51249', 'labevents_t51250', 'labevents_t51254', 'labevents_t51256', 'labevents_t51265', 'labevents_t51274', 'labevents_t51275', 'labevents_t51277', 'labevents_t51279', 'labevents_t51345', 'labevents_t51347', 'labevents_t51355', 'labevents_t51367', 'labevents_t51368', 'labevents_t51375', 'labevents_t51379', 'labevents_t51387', 'labevents_t51419', 'labevents_t51427', 'labevents_t51442', 'labevents_t51444', 'labevents_t51446', 'labevents_t51474', 'labevents_t51478', 'labevents_t51480', 'labevents_t51491', 'labevents_t51498', 'inputevents_t30005', 'inputevents_t30008', 'inputevents_t30023', 'inputevents_t30027', 'inputevents_t30043', 'inputevents_t30044', 'inputevents_t30051', 'inputevents_t30056', 'inputevents_t30059', 'inputevents_t30065', 'inputevents_t30118', 'inputevents_t30124', 'inputevents_t30126', 'inputevents_t30131', 'inputevents_t30144', 'inputevents_t30297', 'outputevents_t40054', 'outputevents_t40085', 'outputevents_t43703', 'outputevents_t226573', 'outputevents_t226580', 'outputevents_t226588', 'outputevents_t226589', 'outputevents_t226599', 'outputevents_t226626', 'outputevents_t226633', 'outputevents_t227510', 'DBSOURCE', 'FIRST_CAREUNIT', 'LAST_CAREUNIT', 'INTIME', 'OUTTIME', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME', 'ETHNICITY', 'INSURANCE', 'GENDER', 'DOB', 'current_admission_dischtime', 'next_admission_icu_intime', 'age_bucket_15-29', 'age_bucket_30-49', 'age_bucket_50-69', 'age_bucket_70-89', 'categorized_ethnicity_Asian', 'categorized_ethnicity_Black', 'categorized_ethnicity_Hispanic', 'categorized_ethnicity_Other', 'categorized_ethnicity_White', 'categorized_insurance_Government', 'categorized_insurance_Medicaid', 'categorized_insurance_Medicare', 'categorized_insurance_Private', 'categorized_insurance_Self Pay', 'mechanical_ventilation']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertModel, BertConfig\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, precision_score, recall_score, f1_score,\n",
    "    average_precision_score, confusion_matrix\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load and Preprocess the Dataset\n",
    "df = pd.read_csv('final_structured_with_mechanical_ventilation.csv')\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Dataset columns:\", df.columns.tolist())\n",
    "\n",
    "unique_diseases = df['hadm_id'].unique()\n",
    "disease_mapping = {d: i for i, d in enumerate(unique_diseases)}\n",
    "df['mapped_disease_id'] = df['hadm_id'].map(disease_mapping)\n",
    "\n",
    "unique_ages = sorted(df['age'].unique())\n",
    "age_mapping = {age: i for i, age in enumerate(unique_ages)}\n",
    "df['age_code'] = df['age'].map(age_mapping)\n",
    "\n",
    "if 'categorized_ethnicity' not in df.columns:\n",
    "    if 'ETHNICITY' in df.columns:\n",
    "        df['categorized_ethnicity'] = df['ETHNICITY'].fillna('Other').str.upper().str.strip()\n",
    "    elif 'ethnicity' in df.columns:\n",
    "        df['categorized_ethnicity'] = df['ethnicity'].fillna('Other').str.upper().str.strip()\n",
    "    else:\n",
    "        df['categorized_ethnicity'] = 'OTHER'\n",
    "        \n",
    "if 'categorized_ethnicity_code' not in df.columns:\n",
    "    df['categorized_ethnicity_code'] = df['categorized_ethnicity'].astype('category').cat.codes\n",
    "\n",
    "# --- Convert other categorical features to codes ---\n",
    "if 'GENDER' in df.columns:\n",
    "    df['GENDER'] = df['GENDER'].astype('category').cat.codes\n",
    "elif 'gender' in df.columns:\n",
    "    df['gender'] = df['gender'].astype('category').cat.codes\n",
    "\n",
    "if 'INSURANCE' in df.columns:\n",
    "    df['INSURANCE'] = df['INSURANCE'].astype('category').cat.codes\n",
    "elif 'insurance' in df.columns:\n",
    "    df['insurance'] = df['insurance'].astype('category').cat.codes\n",
    "\n",
    "if 'FIRST_WARDID' in df.columns:\n",
    "    unique_first_wards = df['FIRST_WARDID'].unique()\n",
    "    first_ward_mapping = {ward: i for i, ward in enumerate(unique_first_wards)}\n",
    "    df['first_ward_code'] = df['FIRST_WARDID'].map(first_ward_mapping)\n",
    "else:\n",
    "    df['first_ward_code'] = 0\n",
    "\n",
    "# For LAST_WARDID (discharge location)\n",
    "if 'LAST_WARDID' in df.columns:\n",
    "    unique_last_wards = df['LAST_WARDID'].unique()\n",
    "    last_ward_mapping = {ward: i for i, ward in enumerate(unique_last_wards)}\n",
    "    df['last_ward_code'] = df['LAST_WARDID'].map(last_ward_mapping)\n",
    "else:\n",
    "    df['last_ward_code'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79d6312f-fd0b-405f-a7e2-472cee59133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Prepare Sequences for Model Input\n",
    "def prepare_sequences(df):\n",
    "    patients = df['subject_id'].unique()\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    patient_ids = []\n",
    "    \n",
    "    for patient in patients:\n",
    "        patient_data = df[df['subject_id'] == patient]\n",
    "        disease_sequence = patient_data['mapped_disease_id'].tolist()\n",
    "        age_sequence = patient_data['age_code'].tolist()\n",
    "        if 'first_ward_code' in patient_data.columns:\n",
    "            admission_loc_sequence = patient_data['first_ward_code'].tolist()\n",
    "        else:\n",
    "            admission_loc_sequence = [0] * len(disease_sequence)\n",
    "        if 'last_ward_code' in patient_data.columns:\n",
    "            discharge_loc_sequence = patient_data['last_ward_code'].tolist()\n",
    "        else:\n",
    "            discharge_loc_sequence = [0] * len(disease_sequence)\n",
    "        segment_sequence = [0 if i % 2 == 0 else 1 for i in range(len(disease_sequence))]\n",
    "        if 'GENDER' in patient_data.columns:\n",
    "            gender_sequence = patient_data['GENDER'].tolist()\n",
    "        elif 'gender' in patient_data.columns:\n",
    "            gender_sequence = patient_data['gender'].tolist()\n",
    "        else:\n",
    "            gender_sequence = [0] * len(disease_sequence)\n",
    "        ethnicity_sequence = patient_data['categorized_ethnicity_code'].tolist()\n",
    "        if 'INSURANCE' in patient_data.columns:\n",
    "            insurance_sequence = patient_data['INSURANCE'].tolist()\n",
    "        elif 'insurance' in patient_data.columns:\n",
    "            insurance_sequence = patient_data['insurance'].tolist()\n",
    "        else:\n",
    "            insurance_sequence = [0] * len(disease_sequence)\n",
    "            \n",
    "        sequences.append({\n",
    "            'diseases': disease_sequence,\n",
    "            'age': age_sequence,\n",
    "            'admission_loc': admission_loc_sequence,\n",
    "            'discharge_loc': discharge_loc_sequence,\n",
    "            'segment': segment_sequence,\n",
    "            'gender': gender_sequence,\n",
    "            'ethnicity': ethnicity_sequence,\n",
    "            'insurance': insurance_sequence\n",
    "        })\n",
    "        mechanical_ventilation_label = patient_data['mechanical_ventilation'].max()\n",
    "        labels.append(mechanical_ventilation_label)\n",
    "        patient_ids.append(patient)\n",
    "    return sequences, labels, patient_ids\n",
    "\n",
    "sequences, labels, patient_ids = prepare_sequences(df)\n",
    "\n",
    "def pad_sequences(sequences, max_len):\n",
    "    return [seq + [0] * (max_len - len(seq)) for seq in sequences]\n",
    "\n",
    "max_len = max(len(seq['diseases']) for seq in sequences)\n",
    "\n",
    "input_ids = pad_sequences([seq['diseases'] for seq in sequences], max_len)\n",
    "age_ids = pad_sequences([seq['age'] for seq in sequences], max_len)\n",
    "segment_ids = pad_sequences([seq['segment'] for seq in sequences], max_len)\n",
    "admission_loc_ids = pad_sequences([seq['admission_loc'] for seq in sequences], max_len)\n",
    "discharge_loc_ids = pad_sequences([seq['discharge_loc'] for seq in sequences], max_len)\n",
    "gender_ids = pad_sequences([seq['gender'] for seq in sequences], max_len)\n",
    "ethnicity_ids = pad_sequences([seq['ethnicity'] for seq in sequences], max_len)\n",
    "insurance_ids = pad_sequences([seq['insurance'] for seq in sequences], max_len)\n",
    "\n",
    "# Convert lists to PyTorch tensors.\n",
    "input_ids_tensor = torch.tensor(input_ids, dtype=torch.long)\n",
    "age_ids_tensor = torch.tensor(age_ids, dtype=torch.long)\n",
    "segment_ids_tensor = torch.tensor(segment_ids, dtype=torch.long)\n",
    "admission_loc_ids_tensor = torch.tensor(admission_loc_ids, dtype=torch.long)\n",
    "discharge_loc_ids_tensor = torch.tensor(discharge_loc_ids, dtype=torch.long)\n",
    "gender_ids_tensor = torch.tensor(gender_ids, dtype=torch.long)\n",
    "ethnicity_ids_tensor = torch.tensor(ethnicity_ids, dtype=torch.long)\n",
    "insurance_ids_tensor = torch.tensor(insurance_ids, dtype=torch.long)\n",
    "labels_tensor = torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "# Create a TensorDataset and DataLoader for training.\n",
    "dataset = TensorDataset(\n",
    "    input_ids_tensor, age_ids_tensor, segment_ids_tensor,\n",
    "    admission_loc_ids_tensor, discharge_loc_ids_tensor,\n",
    "    gender_ids_tensor, ethnicity_ids_tensor, insurance_ids_tensor,\n",
    "    labels_tensor\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80d992de-9746-4868-a552-2c7c1d6c15af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEHRTModel(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(33138, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (age_embedding): Embedding(75, 768)\n",
      "  (segment_embedding): Embedding(2, 768)\n",
      "  (admission_loc_embedding): Embedding(14, 768)\n",
      "  (discharge_loc_embedding): Embedding(14, 768)\n",
      "  (gender_embedding): Embedding(2, 768)\n",
      "  (ethnicity_embedding): Embedding(41, 768)\n",
      "  (insurance_embedding): Embedding(5, 768)\n",
      "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 3. Define the BEHRT Model for Mechanical Ventilation Prediction\n",
    "class BEHRTModel(nn.Module):\n",
    "    def __init__(self, num_diseases, num_ages, num_segments, num_admission_locs, num_discharge_locs, \n",
    "                 num_genders, num_ethnicities, num_insurances, hidden_size=768):\n",
    "        super(BEHRTModel, self).__init__()\n",
    "        config = BertConfig(\n",
    "            vocab_size=num_diseases,\n",
    "            hidden_size=hidden_size,\n",
    "            num_hidden_layers=12,\n",
    "            num_attention_heads=12,\n",
    "            intermediate_size=3072,\n",
    "            max_position_embeddings=512,\n",
    "            type_vocab_size=num_segments,\n",
    "            hidden_dropout_prob=0.1,\n",
    "            attention_probs_dropout_prob=0.1\n",
    "        )\n",
    "        self.bert = BertModel(config)\n",
    "        self.age_embedding = nn.Embedding(num_ages, hidden_size)\n",
    "        self.segment_embedding = nn.Embedding(num_segments, hidden_size)\n",
    "        self.admission_loc_embedding = nn.Embedding(num_admission_locs, hidden_size)\n",
    "        self.discharge_loc_embedding = nn.Embedding(num_discharge_locs, hidden_size)\n",
    "        self.gender_embedding = nn.Embedding(num_genders, hidden_size)\n",
    "        self.ethnicity_embedding = nn.Embedding(num_ethnicities, hidden_size)\n",
    "        self.insurance_embedding = nn.Embedding(num_insurances, hidden_size)\n",
    "        self.classifier = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, age_ids, segment_ids, admission_loc_ids, discharge_loc_ids, \n",
    "                gender_ids, ethnicity_ids, insurance_ids, attention_mask=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs.last_hidden_state  # [batch, seq_len, hidden_size]\n",
    "        \n",
    "        age_embeds = self.age_embedding(age_ids)\n",
    "        segment_embeds = self.segment_embedding(segment_ids)\n",
    "        admission_loc_embeds = self.admission_loc_embedding(admission_loc_ids)\n",
    "        discharge_loc_embeds = self.discharge_loc_embedding(discharge_loc_ids)\n",
    "        gender_embeds = self.gender_embedding(gender_ids)\n",
    "        ethnicity_embeds = self.ethnicity_embedding(ethnicity_ids)\n",
    "        insurance_embeds = self.insurance_embedding(insurance_ids)\n",
    "        \n",
    "        combined_output = (sequence_output + age_embeds + segment_embeds +\n",
    "                           admission_loc_embeds + discharge_loc_embeds +\n",
    "                           gender_embeds + ethnicity_embeds + insurance_embeds)\n",
    "        \n",
    "        cls_token = combined_output[:, 0, :]  # Use [CLS] token\n",
    "        logits = self.classifier(cls_token).squeeze(1)\n",
    "        return logits\n",
    "\n",
    "# Determine sizes for embeddings.\n",
    "num_diseases = len(disease_mapping)\n",
    "num_ages = len(unique_ages)\n",
    "num_segments = 2\n",
    "num_admission_locs = df['first_ward_code'].nunique() if 'first_ward_code' in df.columns else 14\n",
    "num_discharge_locs = df['last_ward_code'].nunique() if 'last_ward_code' in df.columns else 14\n",
    "num_genders = df['GENDER'].nunique() if 'GENDER' in df.columns else df['gender'].nunique()\n",
    "num_ethnicities = df['categorized_ethnicity_code'].nunique()\n",
    "num_insurances = df['INSURANCE'].nunique() if 'INSURANCE' in df.columns else df['insurance'].nunique()\n",
    "\n",
    "model = BEHRTModel(\n",
    "    num_diseases=num_diseases,\n",
    "    num_ages=num_ages,\n",
    "    num_segments=num_segments,\n",
    "    num_admission_locs=num_admission_locs,\n",
    "    num_discharge_locs=num_discharge_locs,\n",
    "    num_genders=num_genders,\n",
    "    num_ethnicities=num_ethnicities,\n",
    "    num_insurances=num_insurances,\n",
    "    hidden_size=768\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0184e3b4-d600-4d1b-8ba3-99c1b16c62e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define Loss, Optimizer, and Scheduler\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=2, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dcb0484-4660-4fcd-b59a-bb40817b4031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Total Loss: 12209.3030\n",
      "Epoch 2/10 - Total Loss: 11494.6544\n",
      "Epoch 3/10 - Total Loss: 10834.1006\n",
      "Epoch 4/10 - Total Loss: 9001.4561\n",
      "Epoch 5/10 - Total Loss: 6222.0880\n",
      "Epoch 6/10 - Total Loss: 5922.5851\n",
      "Epoch 7/10 - Total Loss: 5684.0352\n",
      "Epoch 8/10 - Total Loss: 5340.6424\n",
      "Epoch 9/10 - Total Loss: 5301.8580\n",
      "Epoch 10/10 - Total Loss: 5232.0941\n"
     ]
    }
   ],
   "source": [
    "# 5. Training Loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in dataloader:\n",
    "        (input_ids, age_ids, segment_ids, admission_loc_ids, discharge_loc_ids,\n",
    "         gender_ids, ethnicity_ids, insurance_ids, labels) = batch\n",
    "\n",
    "        input_ids = input_ids.to(device)\n",
    "        age_ids = age_ids.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        admission_loc_ids = admission_loc_ids.to(device)\n",
    "        discharge_loc_ids = discharge_loc_ids.to(device)\n",
    "        gender_ids = gender_ids.to(device)\n",
    "        ethnicity_ids = ethnicity_ids.to(device)\n",
    "        insurance_ids = insurance_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        attention_mask = (input_ids != 0).long().to(device)\n",
    "        logits = model(\n",
    "            input_ids=input_ids,\n",
    "            age_ids=age_ids,\n",
    "            segment_ids=segment_ids,\n",
    "            admission_loc_ids=admission_loc_ids,\n",
    "            discharge_loc_ids=discharge_loc_ids,\n",
    "            gender_ids=gender_ids,\n",
    "            ethnicity_ids=ethnicity_ids,\n",
    "            insurance_ids=insurance_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * input_ids.size(0)\n",
    "    avg_loss = total_loss / len(dataset)\n",
    "    scheduler.step(avg_loss)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Total Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab001a2f-f291-469e-959d-13a364a95bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results for Mechanical Ventilation Prediction:\n",
      "AUROC: 0.9702540997211105\n",
      "AUPRC: 0.9955911805323694\n",
      "Precision: 0.9587256332051453\n",
      "Recall: 0.9881432378869678\n",
      "F1 Score: 0.9732121823994616\n"
     ]
    }
   ],
   "source": [
    "# 6. Evaluation Function\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_logits = []\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            (input_ids, age_ids, segment_ids, admission_loc_ids, discharge_loc_ids,\n",
    "             gender_ids, ethnicity_ids, insurance_ids, labels) = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            age_ids = age_ids.to(device)\n",
    "            segment_ids = segment_ids.to(device)\n",
    "            admission_loc_ids = admission_loc_ids.to(device)\n",
    "            discharge_loc_ids = discharge_loc_ids.to(device)\n",
    "            gender_ids = gender_ids.to(device)\n",
    "            ethnicity_ids = ethnicity_ids.to(device)\n",
    "            insurance_ids = insurance_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            attention_mask = (input_ids != 0).long().to(device)\n",
    "            logits = model(\n",
    "                input_ids=input_ids,\n",
    "                age_ids=age_ids,\n",
    "                segment_ids=segment_ids,\n",
    "                admission_loc_ids=admission_loc_ids,\n",
    "                discharge_loc_ids=discharge_loc_ids,\n",
    "                gender_ids=gender_ids,\n",
    "                ethnicity_ids=ethnicity_ids,\n",
    "                insurance_ids=insurance_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            all_logits.extend(logits.cpu().numpy())\n",
    "            preds = torch.sigmoid(logits)\n",
    "            all_predictions.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    all_logits = np.array(all_logits)\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "    try:\n",
    "        auroc = roc_auc_score(all_labels, all_predictions)\n",
    "    except ValueError:\n",
    "        auroc = float('nan')\n",
    "    auprc = average_precision_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, (all_predictions >= 0.5).astype(int), zero_division=0)\n",
    "    recall = recall_score(all_labels, (all_predictions >= 0.5).astype(int), zero_division=0)\n",
    "    f1 = f1_score(all_labels, (all_predictions >= 0.5).astype(int), zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'logits': all_logits,\n",
    "        'predictions': all_predictions,\n",
    "        'labels': all_labels,\n",
    "        'auroc': auroc,\n",
    "        'auprc': auprc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "evaluation_results = evaluate_model(model, dataloader, device)\n",
    "print(\"Evaluation Results for Mechanical Ventilation Prediction:\")\n",
    "print(\"AUROC:\", evaluation_results['auroc'])\n",
    "print(\"AUPRC:\", evaluation_results['auprc'])\n",
    "print(\"Precision:\", evaluation_results['precision'])\n",
    "print(\"Recall:\", evaluation_results['recall'])\n",
    "print(\"F1 Score:\", evaluation_results['f1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51ff31c4-c3f8-4cd3-ab8a-421d49a837e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d(s) for Age Buckets: {'70-89': -4.0938441116838166e-05, '30-49': 0.0007353867737986795, '50-69': -0.0007255900611237439, '15-29': 0.0032411807890025167}\n",
      "EDDI for Age Buckets: 0.0008505220274498936\n",
      "d(s) for Ethnicity Groups: {'White': 0.0008959306118880055, 'Other': -0.0030577825271334005, 'Black': 0.0027425749015227998, 'Asian': -0.00689110082630656, 'Hispanic': -0.006362452408042927}\n",
      "EDDI for Ethnicity Groups: 0.002055650884541997\n",
      "d(s) for Insurance Groups: {'Other': 0.0}\n",
      "EDDI for Insurance Groups: 0.0\n",
      "Overall EDDI for mechanical ventilation: 0.0007415515474924309\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---- DataFrame merging and demographic column standardization ----\n",
    "results_df = pd.DataFrame({\n",
    "    'subject_id': patient_ids,\n",
    "    'label': evaluation_results['labels'],\n",
    "    'pred_prob': evaluation_results['predictions']\n",
    "})\n",
    "\n",
    "demo_columns = []\n",
    "if 'age' in df.columns:\n",
    "    demo_columns.append('age')\n",
    "if 'ethnicity' in df.columns:\n",
    "    demo_columns.append('ethnicity')\n",
    "elif 'ETHNICITY' in df.columns:\n",
    "    demo_columns.append('ETHNICITY')\n",
    "if 'insurance' in df.columns:\n",
    "    demo_columns.append('insurance')\n",
    "elif 'INSURANCE' in df.columns:\n",
    "    demo_columns.append('INSURANCE')\n",
    "\n",
    "demo_df = df.drop_duplicates(subset='subject_id')[['subject_id'] + demo_columns]\n",
    "results_df = results_df.merge(demo_df, on='subject_id', how='left')\n",
    "\n",
    "# Rename columns to standardize names\n",
    "if 'ETHNICITY' in results_df.columns:\n",
    "    results_df.rename(columns={'ETHNICITY': 'ethnicity'}, inplace=True)\n",
    "if 'INSURANCE' in results_df.columns:\n",
    "    results_df.rename(columns={'INSURANCE': 'insurance'}, inplace=True)\n",
    "\n",
    "# ---- Categorization functions ----\n",
    "def categorize_age(age):\n",
    "    if 15 <= age <= 29:\n",
    "        return '15-29'\n",
    "    elif 30 <= age <= 49:\n",
    "        return '30-49'\n",
    "    elif 50 <= age <= 69:\n",
    "        return '50-69'\n",
    "    else:\n",
    "        return '70-89'\n",
    "\n",
    "def categorize_ethnicity(ethnicity):\n",
    "    eth = ethnicity.upper()\n",
    "    if eth in ['WHITE', 'WHITE - RUSSIAN', 'WHITE - OTHER EUROPEAN', 'WHITE - BRAZILIAN', 'WHITE - EASTERN EUROPEAN']:\n",
    "        return 'White'\n",
    "    elif eth in ['BLACK/AFRICAN AMERICAN', 'BLACK/CAPE VERDEAN', 'BLACK/HAITIAN', 'BLACK/AFRICAN', 'CARIBBEAN ISLAND']:\n",
    "        return 'Black'\n",
    "    elif eth in ['HISPANIC OR LATINO', 'HISPANIC/LATINO - PUERTO RICAN', 'HISPANIC/LATINO - DOMINICAN', 'HISPANIC/LATINO - MEXICAN']:\n",
    "        return 'Hispanic'\n",
    "    elif eth in ['ASIAN', 'ASIAN - CHINESE', 'ASIAN - INDIAN']:\n",
    "        return 'Asian'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "def categorize_insurance(insurance):\n",
    "    ins = str(insurance).upper()\n",
    "    if 'MEDICARE' in ins:\n",
    "        return 'Medicare'\n",
    "    elif 'MEDICAID' in ins:\n",
    "        return 'Medicaid'\n",
    "    elif 'PRIVATE' in ins:\n",
    "        return 'Private'\n",
    "    elif 'GOVERNMENT' in ins:\n",
    "        return 'Government'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "if 'age' in results_df.columns:\n",
    "    results_df['age_bucket'] = results_df['age'].apply(categorize_age)\n",
    "if 'ethnicity' in results_df.columns:\n",
    "    results_df['ethnicity_group'] = results_df['ethnicity'].apply(categorize_ethnicity)\n",
    "if 'insurance' in results_df.columns:\n",
    "    results_df['insurance_group'] = results_df['insurance'].apply(categorize_insurance)\n",
    "\n",
    "# ---- Functions to calculate d(s) and EDDI ----\n",
    "def calculate_d_values(df, sensitive_attr, true_label='label', pred_prob='pred_prob', threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calculates d(s) for each subgroup in the sensitive attribute.\n",
    "    d(s) = (ER_s - OER) / max(OER, 1 - OER)\n",
    "    Returns a dictionary mapping subgroup -> d(s) and the overall error rate.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    df_copy['predicted'] = (df_copy[pred_prob] >= threshold).astype(int)\n",
    "    overall_error = np.mean(df_copy[true_label] != df_copy['predicted'])\n",
    "    \n",
    "    groups = df_copy[sensitive_attr].unique()\n",
    "    d_dict = {}\n",
    "    for group in groups:\n",
    "        group_df = df_copy[df_copy[sensitive_attr] == group]\n",
    "        group_error = np.mean(group_df[true_label] != group_df['predicted'])\n",
    "        d_s = (group_error - overall_error) / max(overall_error, 1 - overall_error)\n",
    "        d_dict[group] = d_s\n",
    "    return d_dict, overall_error\n",
    "\n",
    "def calculate_eddi_from_d(d_dict):\n",
    "    \"\"\"\n",
    "    Computes EDDI for an attribute from its subgroup d(s) values.\n",
    "    EDDI = (sqrt(sum_{s in S} (d(s))^2)) / (number of groups)\n",
    "    \"\"\"\n",
    "    num_groups = len(d_dict)\n",
    "    sum_sq = sum(d**2 for d in d_dict.values())\n",
    "    eddi_attr = np.sqrt(sum_sq) / num_groups\n",
    "    return eddi_attr\n",
    "\n",
    "# Calculate EDDI for each sensitive attribute \n",
    "d_age, oer_age = calculate_d_values(results_df, sensitive_attr='age_bucket')\n",
    "eddi_age = calculate_eddi_from_d(d_age)\n",
    "print(\"d(s) for Age Buckets:\", d_age)\n",
    "print(\"EDDI for Age Buckets:\", eddi_age)\n",
    "\n",
    "d_ethnicity, oer_ethnicity = calculate_d_values(results_df, sensitive_attr='ethnicity_group')\n",
    "eddi_ethnicity = calculate_eddi_from_d(d_ethnicity)\n",
    "print(\"d(s) for Ethnicity Groups:\", d_ethnicity)\n",
    "print(\"EDDI for Ethnicity Groups:\", eddi_ethnicity)\n",
    "\n",
    "d_insurance, oer_insurance = calculate_d_values(results_df, sensitive_attr='insurance_group')\n",
    "eddi_insurance = calculate_eddi_from_d(d_insurance)\n",
    "print(\"d(s) for Insurance Groups:\", d_insurance)\n",
    "print(\"EDDI for Insurance Groups:\", eddi_insurance)\n",
    "\n",
    "# ---- Calculate Overall EDDI ----\n",
    "# Overall EDDI = ( sqrt( eddi_age^2 + eddi_ethnicity^2 + eddi_insurance^2 ) ) / 3\n",
    "overall_eddi = np.sqrt(eddi_age**2 + eddi_ethnicity**2 + eddi_insurance**2) / 3\n",
    "print(\"Overall EDDI for mechanical ventilation:\", overall_eddi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844e4fdf-8119-4dcd-a969-63de8a2e17e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (allennlp_env)",
   "language": "python",
   "name": "allennlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
