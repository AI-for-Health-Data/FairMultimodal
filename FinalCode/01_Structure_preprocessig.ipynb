{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fa4169b-d84f-4162-b968-fdaa27469c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. File saved as 'structured_first_icu_stays_with_gender.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the MIMIC-III datasets\n",
    "admissions = pd.read_csv('ADMISSIONS.csv.gz', compression='gzip')\n",
    "patients = pd.read_csv('PATIENTS.csv.gz', compression='gzip')\n",
    "icu_stays = pd.read_csv('ICUSTAYS.csv.gz', compression='gzip')\n",
    "\n",
    "# Convert relevant columns to datetime format\n",
    "admissions['ADMITTIME'] = pd.to_datetime(admissions['ADMITTIME'])\n",
    "admissions['DISCHTIME'] = pd.to_datetime(admissions['DISCHTIME'])\n",
    "admissions['DEATHTIME'] = pd.to_datetime(admissions['DEATHTIME'])\n",
    "icu_stays['INTIME'] = pd.to_datetime(icu_stays['INTIME'])\n",
    "icu_stays['OUTTIME'] = pd.to_datetime(icu_stays['OUTTIME'])\n",
    "\n",
    "# Rename columns for consistency\n",
    "admissions.rename(columns={'SUBJECT_ID': 'subject_id', 'HADM_ID': 'hadm_id'}, inplace=True)\n",
    "patients.rename(columns={'SUBJECT_ID': 'subject_id'}, inplace=True)\n",
    "icu_stays.rename(columns={'SUBJECT_ID': 'subject_id', 'HADM_ID': 'hadm_id'}, inplace=True)\n",
    "\n",
    "# Merge ICU stays with admissions to include DEATHTIME, DISCHTIME, and ETHNICITY\n",
    "icu_stays = pd.merge(\n",
    "    icu_stays,\n",
    "    admissions[['subject_id', 'hadm_id', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME', 'ETHNICITY', 'INSURANCE']],\n",
    "    on=['subject_id', 'hadm_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge GENDER from patients into ICU stays\n",
    "icu_stays = pd.merge(icu_stays, patients[['subject_id', 'GENDER', 'DOB']], on='subject_id', how='left')\n",
    "\n",
    "# Function to calculate short-term mortality\n",
    "def calculate_short_term_mortality(icu_stays):\n",
    "    icu_stays['short_term_mortality'] = icu_stays['DEATHTIME'].notnull().astype(int)\n",
    "    return icu_stays\n",
    "\n",
    "def calculate_readmission(df):\n",
    "    \"\"\"\n",
    "    Calculate readmission within 30 days.\n",
    "    For each ICU stay, if the next ICU admission (based on INTIME) happens within 30 days \n",
    "    of the current admission's DISCHTIME, label readmission as 1.\n",
    "    \"\"\"\n",
    "    # Check required columns exist\n",
    "    for col in ['DISCHTIME', 'INTIME', 'hadm_id']:\n",
    "        if col not in df.columns:\n",
    "            raise KeyError(f\"{col} column is missing in the input data.\")\n",
    "    \n",
    "    # First, sort by subject, admission time, and ICU intime\n",
    "    df = df.sort_values(by=['subject_id', 'ADMITTIME', 'INTIME'])\n",
    "    \n",
    "    # Get the discharge time of the current admission for each (subject, hadm_id) group\n",
    "    df['current_admission_dischtime'] = df.groupby(['subject_id', 'hadm_id'])['DISCHTIME'].transform('first')\n",
    "    \n",
    "    # Identify the next ICU admission for each patient\n",
    "    df['next_admission_icu_intime'] = df.groupby('subject_id')['INTIME'].shift(-1)\n",
    "    df['next_hadm_id'] = df.groupby('subject_id')['hadm_id'].shift(-1)\n",
    "    \n",
    "    # Calculate readmission: if the next ICU stay occurs within 30 days of the current discharge time\n",
    "    df['readmission_within_30_days'] = (\n",
    "        (df['next_admission_icu_intime'] - df['current_admission_dischtime']).dt.days <= 30\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Fill NaN values with 0 \n",
    "    df['readmission_within_30_days'] = df['readmission_within_30_days'].fillna(0).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the short-term mortality and readmission functions\n",
    "icu_stays = calculate_short_term_mortality(icu_stays)\n",
    "icu_stays = calculate_readmission(icu_stays)\n",
    "\n",
    "# Extract the first ICU stay for each patient\n",
    "first_icu_stays = icu_stays.sort_values(by=['subject_id', 'INTIME']).groupby('subject_id').first().reset_index()\n",
    "\n",
    "# Calculate age at ICU admission\n",
    "def calculate_age(dob, intime):\n",
    "    return intime.year - dob.year - ((intime.month, intime.day) < (dob.month, dob.day))\n",
    "\n",
    "first_icu_stays['age'] = first_icu_stays.apply(lambda x: calculate_age(pd.to_datetime(x['DOB']), x['INTIME']), axis=1)\n",
    "first_icu_stays = first_icu_stays[(first_icu_stays['age'] >= 15) & (first_icu_stays['age'] <= 90)]\n",
    "\n",
    "# Categorize age into buckets\n",
    "def categorize_age(age):\n",
    "    if 15 <= age <= 29:\n",
    "        return '15-29'\n",
    "    elif 30 <= age <= 49:\n",
    "        return '30-49'\n",
    "    elif 50 <= age <= 69:\n",
    "        return '50-69'\n",
    "    else:\n",
    "        return '70-89'\n",
    "\n",
    "first_icu_stays['age_bucket'] = first_icu_stays['age'].apply(categorize_age)\n",
    "\n",
    "# Categorize ethnicity\n",
    "def categorize_ethnicity(ethnicity):\n",
    "    ethnicity = ethnicity.upper()\n",
    "    if ethnicity in ['WHITE', 'WHITE - RUSSIAN', 'WHITE - OTHER EUROPEAN', 'WHITE - BRAZILIAN', 'WHITE - EASTERN EUROPEAN']:\n",
    "        return 'White'\n",
    "    elif ethnicity in ['BLACK/AFRICAN AMERICAN', 'BLACK/CAPE VERDEAN', 'BLACK/HAITIAN', 'BLACK/AFRICAN', 'CARIBBEAN ISLAND']:\n",
    "        return 'Black'\n",
    "    elif ethnicity in [\n",
    "        'HISPANIC OR LATINO', 'HISPANIC/LATINO - PUERTO RICAN', 'HISPANIC/LATINO - DOMINICAN', 'HISPANIC/LATINO - MEXICAN']:\n",
    "        return 'Hispanic'\n",
    "    elif ethnicity in ['ASIAN', 'ASIAN - CHINESE', 'ASIAN - INDIAN']:\n",
    "        return 'Asian'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "first_icu_stays['categorized_ethnicity'] = first_icu_stays['ETHNICITY'].apply(categorize_ethnicity)\n",
    "\n",
    "# Categorize insurance\n",
    "def categorize_insurance(insurance):\n",
    "    if 'MEDICARE' in insurance.upper():\n",
    "        return 'Medicare'\n",
    "    elif 'PRIVATE' in insurance.upper():\n",
    "        return 'Private'\n",
    "    elif 'MEDICAID' in insurance.upper():\n",
    "        return 'Medicaid'\n",
    "    elif 'SELF PAY' in insurance.upper():\n",
    "        return 'Self Pay'\n",
    "    else:\n",
    "        return 'Government'\n",
    "\n",
    "first_icu_stays['categorized_insurance'] = first_icu_stays['INSURANCE'].apply(categorize_insurance)\n",
    "\n",
    "# One-hot encoding for categorical columns (excluding GENDER)\n",
    "first_icu_stays = pd.get_dummies(\n",
    "    first_icu_stays,\n",
    "    columns=['age_bucket', 'categorized_ethnicity', 'categorized_insurance'],\n",
    "    drop_first=False\n",
    ")\n",
    "\n",
    "# Save the structured data\n",
    "first_icu_stays.to_csv('structured_first_icu_stays.csv', index=False)\n",
    "\n",
    "print(\"Processing complete. File saved as 'structured_first_icu_stays_with_gender.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "287b0803-c825-4589-9c70-e98ef093ab46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate patients found in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate patient IDs\n",
    "duplicate_patients = first_icu_stays[first_icu_stays.duplicated(subset=['subject_id'], keep=False)]\n",
    "if duplicate_patients.empty:\n",
    "    print(\"No duplicate patients found in the dataset.\")\n",
    "else:\n",
    "    print(f\"Number of duplicate patients: {duplicate_patients['subject_id'].nunique()}\")\n",
    "    print(\"Details of duplicate patients:\")\n",
    "    print(duplicate_patients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56fa89cc-acd3-431b-9953-9871578c89cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unstructured data shape: (43124, 1053)\n",
      "Structured data shape: (36615, 39)\n",
      "Number of common subject IDs: 33942\n",
      "Filtered structured data shape: (33942, 39)\n",
      "Filtered structured dataset saved as 'filtered_structured_first_icu_stays.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Read the Unstructured Dataset\n",
    "unstructured_file = 'final_unstructured.csv'\n",
    "unstructured_df = pd.read_csv(unstructured_file, engine='python', on_bad_lines='skip')\n",
    "print(f\"Unstructured data shape: {unstructured_df.shape}\")\n",
    "\n",
    "# Read the Structured Dataset\n",
    "structured_file = 'structured_first_icu_stays.csv'\n",
    "structured_df = pd.read_csv(structured_file)\n",
    "print(f\"Structured data shape: {structured_df.shape}\")\n",
    "\n",
    "# Identify the Common Subject IDs\n",
    "unstructured_ids = set(unstructured_df['subject_id'].unique())\n",
    "structured_ids   = set(structured_df['subject_id'].unique())\n",
    "\n",
    "# Compute the intersection of the subject IDs\n",
    "common_ids = unstructured_ids.intersection(structured_ids)\n",
    "print(f\"Number of common subject IDs: {len(common_ids)}\")\n",
    "\n",
    "# Filter the Structured Dataset (Keep only rows in the structured dataset with subject_ids in the common set.)\n",
    "filtered_structured_df = structured_df[structured_df['subject_id'].isin(common_ids)].copy()\n",
    "print(f\"Filtered structured data shape: {filtered_structured_df.shape}\")\n",
    "\n",
    "# Save the Filtered Datasets\n",
    "filtered_structured_df.to_csv('filtered_structured_first_icu_stays.csv', index=False)\n",
    "print(\"Filtered structured dataset saved as 'filtered_structured_first_icu_stays.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "232361ab-3bac-4cb4-bba7-88e9b78a47a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33942, 39), 3525, 3033)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strip whitespace from column names\n",
    "filtered_structured_df.columns = filtered_structured_df.columns.str.strip()\n",
    "\n",
    "# Check the shape of the dataset\n",
    "dataset_shape = filtered_structured_df.shape\n",
    "\n",
    "# Calculate positive cases for short-term mortality\n",
    "positive_mortality_count = filtered_structured_df['short_term_mortality'].sum()\n",
    "\n",
    "# Calculate positive cases for readmission within 30 days\n",
    "positive_readmission_count = filtered_structured_df['readmission_within_30_days'].sum()\n",
    "\n",
    "# Output results\n",
    "dataset_shape, positive_mortality_count, positive_readmission_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fce18b-d11a-49bc-8d78-d97b0b8ca5de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (allennlp_env)",
   "language": "python",
   "name": "allennlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
